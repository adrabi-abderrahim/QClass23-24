{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrabi-abderrahim/QClass23-24/blob/main/Data_reuploading_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook we use data re-uploading encoding method to create a Quantum machine learn model in order to classify Iris flowers named Setosa and Versicolor with thier petal and sepal lenghts.\n",
        "\n",
        "To this end, we use a quantum circuit with only `1 qubit` to achieve an accuracy of `100%`.\n",
        "\n",
        "The code is self-explanatory, it follows the classical steps of machine learning:\n",
        "- Data Encoding,\n",
        "- A model definition, and\n",
        "- A training loop.\n",
        "\n",
        "For the optimizer, we choosed Adam with `learning rate = 0.1`, a neural network with `4` nodes and `1` hidden layer.\n",
        "\n",
        "See [Data-reuploading classifier](https://pennylane.ai/qml/demos/tutorial_data_reuploading_classifier/) for more explanation.\n",
        "\n",
        "**To be honest**, I am inspired from the code in [Undergraduate Thesis: Quantum Image Classifier Design with Data Re-uploading Quantum Convolution and Data Re-uploading Classifier Scheme](https://github.com/ericardomuten/quantum_image_classifier) by Eraraya Ricardo Muten."
      ],
      "metadata": {
        "id": "H-XLXNEBBz9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Hoping to meet the Judging criteria, we will give the following details:*\n",
        "\n",
        "- **QML model**\n",
        "\n",
        "  We used a quantum circuit of `1` qubit as a proof of concept that QML \"could\" be better than classical one. In my reasoning, if we can't use less layers and nodes in QML then classical ML. Then, Quantum ML is useless.\n",
        "\n",
        "  Also, it not a matter of numbers of layers and nodes only, but we need models than train faster, cheaper (in the future maybe), and with a near-perfect accuracy.\n",
        "\n",
        "- **Data uploading / encoding method**\n",
        "\n",
        "  Encoding data to quantum qubits is worst than classical counterparty, even in the simulation case. So, **data re-uploading** gives a smart and cheap (i.e in terms of the number of qubits used not the deep the circuit) way to do so, We liked it.\n",
        "\n",
        "- **Cost function**\n",
        "\n",
        "  We only normalize the sum the absolute values of each fidelity minus `1` i.e. $\\sum_{i}^n \\frac{|1-f_i|}{n}$. It is no need to complicate life and lost time on unnecessary  computations. Remember, we want a fast trainig model.\n",
        "\n",
        "- **Optimization method**\n",
        "\n",
        "  Adam optimizer works fine. We noticed that when `stepsize` is bigger the accuracy start jumping from value to another in a rotation like Grover's Algorithm as we studied."
      ],
      "metadata": {
        "id": "m-Iw9jJfSkQq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LBMKRXX_EHWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d85ecb-0b70-4fdb-f3b5-fb6b1ac6f7df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pennylane --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u9BvSLKtEQVr"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import pennylane.optimize as optz\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import gen_batches\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MUuqW9le44-"
      },
      "source": [
        "# Loading and preprocessing Iris dataset\n",
        "\n",
        "In this section, we will prepare the dataset for training by removing unnecessary features and classes. Also, we will normalize data and pad it for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9Z8fzog1e7N1"
      },
      "outputs": [],
      "source": [
        "# Loading Iris dataset from scikit-lean datasets\n",
        "iris = datasets.load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mwjqmtI2fAVB"
      },
      "outputs": [],
      "source": [
        "# Filter dataset to get indeces of Setosa and Versicolour flowers\n",
        "indexes = np.where(iris.target != 2)\n",
        "\n",
        "# Keep features petal and sepal lengths\n",
        "x_data = iris.data[indexes][:, [0, 2]]\n",
        "\n",
        "# Get classes of Setosa and Versicolour flowers\n",
        "y_data = iris.target[indexes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xi2dJHm6f_8j"
      },
      "outputs": [],
      "source": [
        "# Noramalize data into the interval [-1 , 1]\n",
        "nearest_ceil = 10**6\n",
        "x_data = np.ceil(nearest_ceil * np.cos(np.pi * x_data, requires_grad=False))/nearest_ceil\n",
        "\n",
        "# Assert the normalization\n",
        "assert x_data.min() >= -1\n",
        "assert x_data.max() <= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7ulB_6wQhZ2e"
      },
      "outputs": [],
      "source": [
        "# Since we have only two features and the paper forces the use of the gate Rotation(a, b, c),\n",
        "# we need to pad the dataset to three element per row.\n",
        "x_data = np.hstack((x_data, np.reshape(y_data, (-1, 1))))\n",
        "\n",
        "# Asset the padding\n",
        "assert x_data.shape == (len(indexes[0]), 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsKKazqqoTRZ"
      },
      "source": [
        "# Utils\n",
        "\n",
        "A collection of utils for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zXopxXEa8gRt"
      },
      "outputs": [],
      "source": [
        "# Since (the current) quantum computing is just a linear algebra (with some other stuff). So, we encode the targets using one-hot encoding like this:\n",
        "# 0 -> Some hermitian matrix\n",
        "# 1 -> Some hermitian matrix different for the one for the class \"0\"\n",
        "\n",
        "op_target = np.array([\n",
        "    [[1, 0], [0, 0]],\n",
        "    [[0, 0], [0, 1]],\n",
        "    ], requires_grad=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNdGTwagBeA-"
      },
      "source": [
        "# Quantum Model\n",
        "\n",
        "The model in this case is a quantum circit with one qubit (i.e. wire).\n",
        "The current model is inspered from the demo [Data-reuploading classifier](https://pennylane.ai/qml/demos/tutorial_data_reuploading_classifier/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LwtARaNiBzHM"
      },
      "outputs": [],
      "source": [
        "# The circuit of the model uses only 1 qubit\n",
        "\n",
        "@qml.qnode(qml.device(\"lightning.qubit\", wires = 1))\n",
        "def circuit(params, x, y):\n",
        "\n",
        "  for i in range(len(params[0])):\n",
        "    # Perceptron\n",
        "    qml.Rot(*(params[0][i] * x + params[1][i]), wires=0)\n",
        "\n",
        "  return qml.expval(qml.Hermitian(y, wires=[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xE8aclu2C0Cu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "bc72f0ff-f230-448c-e558-85c0c2fe94c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expectation value:  0.5853897650697074\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show the circuit for one node\n",
        "test_params = [\n",
        "    np.random.uniform(size=(1, 3), requires_grad=False),\n",
        "    np.random.uniform(size=(1, 3), requires_grad=False),\n",
        "    ]\n",
        "qml.draw_mpl(circuit, style='pennylane')(test_params, test_params[0][0], op_target[0])\n",
        "print('Expectation value: ', circuit(test_params, test_params[0][0], op_target[0]))\n",
        "\n",
        "del test_params"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cost Function\n",
        "\n",
        "Here, the cost function is defined and it uses the quantum circuit to calculate the fidelities of the entries passed via input."
      ],
      "metadata": {
        "id": "EpOHtp4fW6IG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "waeeBxHTXb4e"
      },
      "outputs": [],
      "source": [
        "# Summing the fidelities for all the data points after passing through the circuit\n",
        "def cost(params, x, y):\n",
        "  loss = 0.0\n",
        "  for i in range(len(x)):\n",
        "    f = circuit(params, x[i], op_target[y[i]])\n",
        "    # Keep it simple\n",
        "    loss = loss + np.abs(1 - f)\n",
        "  return loss / len(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jCxjqN9svEyw"
      },
      "outputs": [],
      "source": [
        "# Predict the class of an input using parameters on the quantum circuit\n",
        "def predict(params, x):\n",
        "  fidelity_values = []\n",
        "  predicted = []\n",
        "\n",
        "  for i in range(len(x)):\n",
        "    fidelities = [circuit(params, x[i], t) for t in op_target]\n",
        "    best_fidel = np.argmax(fidelities)\n",
        "    predicted.append(best_fidel)\n",
        "    fidelity_values.append(fidelities)\n",
        "\n",
        "  return np.array(predicted), np.array(fidelity_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg9wbBnWSbNm"
      },
      "source": [
        "# Training Loop\n",
        "\n",
        "The training loop that uses an optimazer to find best parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tpdkR2T-UVue"
      },
      "outputs": [],
      "source": [
        "# Training parameters\n",
        "num_nodes = 4\n",
        "learning_rate = 0.1\n",
        "epochs = 10\n",
        "batch_size = 2**3\n",
        "\n",
        "# Splitting data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.20, random_state=53)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the optimizer\n",
        "opt = optz.AdamOptimizer(learning_rate)\n",
        "\n",
        "params = np.array([\n",
        "  np.random.uniform(size=(num_nodes, 3)), # Weights\n",
        "  np.random.uniform(size=(num_nodes, 3))  # Biais\n",
        "])"
      ],
      "metadata": {
        "id": "hWkaIr3Ay3Sv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z6nzS8PbhhC-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "93b47f45-c21a-45f3-ebf5-d9bc688271fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 | Loss: 0.314594 | Train accuracy: 0.787500 | Test accuracy: 0.900000\n",
            "Epoch:  2 | Loss: 0.104709 | Train accuracy: 1.000000 | Test accuracy: 1.000000\n",
            "Epoch:  3 | Loss: 0.034892 | Train accuracy: 1.000000 | Test accuracy: 1.000000\n",
            "Epoch:  4 | Loss: 0.017264 | Train accuracy: 1.000000 | Test accuracy: 1.000000\n",
            "Epoch:  5 | Loss: 0.004646 | Train accuracy: 1.000000 | Test accuracy: 1.000000\n",
            "Epoch:  6 | Loss: 0.004377 | Train accuracy: 1.000000 | Test accuracy: 1.000000\n",
            "Epoch:  7 | Loss: 0.002083 | Train accuracy: 1.000000 | Test accuracy: 1.000000\n",
            "Epoch:  8 | Loss: 0.000604 | Train accuracy: 1.000000 | Test accuracy: 1.000000\n",
            "Epoch:  9 | Loss: 0.000245 | Train accuracy: 1.000000 | Test accuracy: 1.000000\n",
            "Epoch: 10 | Loss: 0.000227 | Train accuracy: 1.000000 | Test accuracy: 1.000000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>&#127881 Jackpot!</h1>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "accuracy_train, accuracy_test = 0, 0\n",
        "\n",
        "# The training loop\n",
        "for e in range(epochs):\n",
        "\n",
        "  # Train the batch of the dataset\n",
        "  for idx in gen_batches(len(x_train), batch_size):\n",
        "      params, _, _= opt.step(cost, params, x_train[idx], y_train[idx])\n",
        "\n",
        "  # Get the predicted results using training dataset\n",
        "  predicted_train, fidel_train = predict(params, x_train)\n",
        "  accuracy_train = metrics.accuracy_score(y_train, predicted_train)\n",
        "\n",
        "  # Calculate the loss\n",
        "  loss = cost(params, x_train, y_train)\n",
        "\n",
        "  # Get the predicted results using testing dataset to compare the behaviour\n",
        "  # of the model on the training dataset and test dataset.\n",
        "  predicted_test, fidel_test = predict(params, x_test)\n",
        "  accuracy_test = metrics.accuracy_score(y_test, predicted_test)\n",
        "\n",
        "  # Print important information on the screen\n",
        "  res = [e + 1, loss, accuracy_train, accuracy_test]\n",
        "  print(\"Epoch: {:2d} | Loss: {:3f} | Train accuracy: {:3f} | Test accuracy: {:3f}\".format(*res))\n",
        "\n",
        "# Show an emoji if the accuracy of the training and testing is 100%\n",
        "if accuracy_train == 1 and accuracy_test == 1:\n",
        "    display(HTML('<h1>&#127881 Jackpot!</h1>'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Just predict all the element of the dataset at once\n",
        "x_data_prediction, x_data_fidels = predict(params, x_data)\n",
        "accuracy_x_data = metrics.accuracy_score(y_data, x_data_prediction)\n",
        "print('The accuracy of all dataset is:', accuracy_x_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lBBozwm9I-U",
        "outputId": "15a677d7-cc07-4319-874e-b778fde01aa9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy of all dataset is: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NLiIpdTjaZaq"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNj6goJOycHM2kvT9CK5tfj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}